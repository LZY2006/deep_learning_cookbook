{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Installing gutenberg is tricky, so it is not included in the requirements.txt\n",
    "# For it to work we need a berkelydb version <= 6 for licensing reasons. On OSX\n",
    "# using brew you can do:\n",
    "#   brew install berkeley-db@4\n",
    "\n",
    "# !wget \"https://download.lfd.uci.edu/pythonlibs/z4tqcw5k/bsddb3-6.2.9-cp37-cp37m-win_amd64.whl\"\n",
    "# !pip install \"bsddb3-6.2.9-cp37-cp37m-win_amd64.whl\"\n",
    "\n",
    "# !pip install gutenberg\n",
    "\n",
    "# If this doesn't work, this notebook should still run, just not fetching data\n",
    "# from gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    GUTENBERG = True\n",
    "    from gutenberg.acquire import load_etext\n",
    "    from gutenberg.query import get_etexts, get_metadata\n",
    "    from gutenberg.acquire import get_metadata_cache\n",
    "    from gutenberg.acquire.text import UnknownDownloadUriException\n",
    "    from gutenberg.cleanup import strip_headers\n",
    "    from gutenberg._domain_model.exceptions import CacheAlreadyExistsException\n",
    "except ImportError:\n",
    "    GUTENBERG = False\n",
    "    print('Gutenberg is not installed. See instructions at https://pypi.python.org/pypi/Gutenberg')\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense, Dropout, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "import keras.callbacks\n",
    "import keras.backend as K\n",
    "import scipy.misc\n",
    "import json\n",
    "\n",
    "import os, sys\n",
    "import re\n",
    "import PIL\n",
    "from PIL import ImageDraw\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import get_file\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "try:\n",
    "    from io import BytesIO\n",
    "except ImportError:\n",
    "    from StringIO import StringIO as BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if GUTENBERG:\n",
    "#     shakespeare = strip_headers(load_etext(100))\n",
    "# else:\n",
    "#     path = get_file('shakespeare', 'https://storage.googleapis.com/deep-learning-cookbook/100-0.txt')\n",
    "#     shakespeare = open(path).read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190418"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text = open(r\"C:\\Users\\zdwxx\\Desktop\\30841409578290.txt\", encoding=\"utf-8\").read()\n",
    "len(training_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2928"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = list(sorted(set(training_text)))\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'电网理论的，是建立教学模型的高手，算不上科幻迷但也是爱好者，他对我那个错误百出的模型进行了修正。软件运行时最多的一次曾在十万光年半径内设定了三十万个文明，这个用现在看来很简陋的tubo c编的程序在286机上运行了几个小时，结果很有趣。当然，我只是个工程师，没有能力进行这样级别的研究，只是一个科幻迷玩玩儿而已，从科学角度讲得出的结果肯定没什么意义，但从科幻角度讲却极有价值，因为那些结果展示的宇宙间点状文明的演化图景，不管正确与否，其诡异程度是很难凭空想出来的。\\n我认为零道德的文明宇宙完全可能存在，有道德的人类文明如何在这样一个宇宙中生存？这就是我写《地球往事》的初衷。当然，《三体》并没有揭示那个宇宙文明的图景，其中的两大文明自己也没有意识到这个图景，只是揭开了其面纱的一角。比如，既然距我们最近的恒星都有智慧文明，那这个宇宙一定是十分拥挤的，可为什么它看起来却如此空旷？但愿有机会在《地球往事》 的第二部中继续描述。\\n那个将在《 地球往事》中渐渐展开的图景，肯定会让敬畏心中道德的读者不舒服，但只是科幻而已，不必当真。：）\\n从《三体》连载中得知，国内科幻读者喜欢描述宇宙终极图景的科幻小说，这多少让人感到有些意外。我是从八十年代的科幻高潮中过来的，个人认为那时的作家们创造了真正的、以后再也没有成规模出现过的中国式科幻，这种科幻最显著的特点就是完全技术细节化，没有形而上的影子。而现在的科幻迷们已经打开了天眼，用思想拥抱整个宇宙了。这也对科幻小说作者提出了更高的要求，很遗憾《三体》不是这样的\"终级科幻小说\".创作《2001》式的科幻是很难的，特别是长篇，很容易成为既无小说的生动，又无科普的正确，更无论文的严谨的一堆空架子，笔者对此还没有信心。\\n哦，这个设想中的系列叫《地球往事》，没有太多的意思，科幻与其他幻想文学的区别就在于它与真实还牵着一根细线，这就使它成为现代神话而不是童话（古代神话在当时的读者心中是真实的）。所以我一直认为，好看的科幻小说应该是把最空灵最疯狂的想象写得像新闻报道一般真实。往事的回忆总是真实的，自己希望把小说写得像是历史学家对过去的真实记叙，但能不能做到，就是另一回事了。设想中《地球往事》的下一部暂名为《黑暗森林》，取自八十年代流行过的一句话：\"城市就是森林，每一个男人都是猎手，每一个女人都是陷阱。\"\\n哦，最后说的当然是最重要的：谢谢大家！ （ 刘慈欣 ）\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_text[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_rnn_model(num_chars, num_layers, num_nodes=512, dropout=0.1):\n",
    "#     input = Input(shape=(None, num_chars), name='input')\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Input(shape=(num_chars)))\n",
    "    model.add(Embedding(num_chars, 256))\n",
    "#     model.add(tf.keras.layers.Flatten(data_format=\"channels_first\"))\n",
    "    \n",
    "#     model.add(tf.keras.layers.Lambda(lambda x: tf.reshape(model.output, [-1,-1,256*num_chars])))\n",
    "    for i in range(num_layers):\n",
    "        model.add(LSTM(num_nodes, return_sequences=True, name='lstm_layer_%d' % (i + 1)))\n",
    "        if dropout:\n",
    "            model.add(Dropout(dropout))\n",
    "        else:\n",
    "            pass\n",
    "    model.add(TimeDistributed(Dense(num_chars, name='dense', activation='softmax')))\n",
    "#     model = Model(inputs=[input], outputs=[dense])\n",
    "    optimizer = Adam(lr=5e-4)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 2928, 256)         749568    \n",
      "_________________________________________________________________\n",
      "lstm_layer_1 (LSTM)          (None, 2928, 640)         2296320   \n",
      "_________________________________________________________________\n",
      "lstm_layer_2 (LSTM)          (None, 2928, 640)         3279360   \n",
      "_________________________________________________________________\n",
      "lstm_layer_3 (LSTM)          (None, 2928, 640)         3279360   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 2928, 2928)        1876848   \n",
      "=================================================================\n",
      "Total params: 11,481,456\n",
      "Trainable params: 11,481,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = char_rnn_model(len(chars), num_layers=3, num_nodes=640, dropout=0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2928)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHUNK_SIZE = 10\n",
    "\n",
    "def data_generator(all_text, char_to_idx, batch_size, chunk_size):\n",
    "    X = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
    "    y = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
    "    while True:\n",
    "        for row in range(batch_size):\n",
    "            idx = random.randrange(len(all_text) - chunk_size - 1)\n",
    "            chunk = np.zeros((chunk_size + 1, len(char_to_idx)))\n",
    "            for i in range(chunk_size + 1):\n",
    "                chunk[i, char_to_idx[all_text[idx + i]]] = 1\n",
    "            X[row, :, :] = chunk[:chunk_size]\n",
    "            y[row, :, :] = chunk[1:]\n",
    "        X = X.reshape([batch_size*chunk_size, len(char_to_idx)])\n",
    "        y = y.reshape([batch_size*chunk_size, len(char_to_idx)])\n",
    "        yield X, y\n",
    "\n",
    "next(data_generator(training_text, char_to_idx, 4, chunk_size=CHUNK_SIZE))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-a1bbd3cb8770>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": " [_Derived_]RecvAsync is cancelled.\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_43}}]]\n\t [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_40]] [Op:__inference_train_function_8072]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a1bbd3cb8770>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_text\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\zdwxx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zdwxx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1829\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32mc:\\users\\zdwxx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zdwxx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zdwxx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zdwxx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zdwxx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zdwxx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zdwxx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zdwxx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\zdwxx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCancelledError\u001b[0m:  [_Derived_]RecvAsync is cancelled.\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_43}}]]\n\t [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_40]] [Op:__inference_train_function_8072]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "early = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                              min_delta=0.03,\n",
    "                              patience=3,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "model.fit_generator(\n",
    "    data_generator(training_text, char_to_idx, batch_size=BATCH_SIZE, chunk_size=CHUNK_SIZE),\n",
    "    epochs=20,\n",
    "    callbacks=[early,],\n",
    "    steps_per_epoch=int(2 * len(training_text) / (BATCH_SIZE * CHUNK_SIZE)),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('zoo/06/shakespeare.json', 'w') as fout:\n",
    "    json.dump({\n",
    "        'chars': ''.join(chars),\n",
    "        'char_to_idx': char_to_idx,\n",
    "        'chunk_size': CHUNK_SIZE,\n",
    "    }, fout)\n",
    "model.save('zoo/06/shakespeare.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"zoo/06/shakespeare.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_output(model, training_text, gened, start_index=None, diversity=None, amount=400):\n",
    "    if start_index is None:\n",
    "        start_index = random.randint(0, len(training_text) - CHUNK_SIZE - 1)\n",
    "    generated = training_text[start_index: start_index + CHUNK_SIZE]\n",
    "#     generated = gened\n",
    "#     generated = \"什么\"\n",
    "    yield generated + '#'\n",
    "    for i in range(amount):\n",
    "        x = np.zeros((1, len(generated), len(chars)))\n",
    "        for t, char in enumerate(generated):\n",
    "            x[0, t, char_to_idx[char]] = 1.\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        if diversity is None:\n",
    "            next_index = np.argmax(preds[len(generated) - 1])\n",
    "        else:\n",
    "            preds = np.asarray(preds[len(generated) - 1]).astype('float64')\n",
    "            preds = np.log(preds) / diversity\n",
    "            exp_preds = np.exp(preds)\n",
    "            preds = exp_preds / np.sum(exp_preds)\n",
    "            probas = np.random.multinomial(1, preds, 1)\n",
    "            next_index = np.argmax(probas)     \n",
    "        next_char = chars[next_index]\n",
    "        yield next_char\n",
    "\n",
    "        generated += next_char\n",
    "    return generated\n",
    "\n",
    "for ch in generate_output(model, training_text, \"\"):\n",
    "    sys.stdout.write(ch)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_python(rootdir):\n",
    "    matches = []\n",
    "    for root, dirnames, filenames in os.walk(rootdir):\n",
    "        for fn in filenames:\n",
    "            if fn.endswith('.py'):\n",
    "                matches.append(os.path.join(root, fn))\n",
    "\n",
    "    return matches\n",
    "#  + find_python(os.path.join(sys.executable.rsplit('/', 2)[0], 'lib'))\n",
    "# srcs = find_python(random.__file__.rsplit('\\\\', 1)[0])\n",
    "torch_dir = r\"C:\\Users\\zdwxx\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\torch\"\n",
    "tensorflow_dir = r\"C:\\Users\\zdwxx\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\tensorflow_core\"\n",
    "srcs = find_python(r\"C:\\python27-x64\\Lib\")\n",
    "len(srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(value):\n",
    "    value = ''.join(ch for ch in value if ord(ch) < 127)\n",
    "    if not ' ' in value:\n",
    "        return value\n",
    "    if sum(1 for ch in value if ch.isalpha()) > 6:\n",
    "        return 'MSG'\n",
    "    return value\n",
    "\n",
    "\n",
    "def replace_literals(st):\n",
    "    res = []\n",
    "    start_text = start_quote = i = 0\n",
    "    quote = ''\n",
    "    while i < len(st):\n",
    "        if quote:\n",
    "            if st[i: i + len(quote)] == quote:\n",
    "                quote = ''\n",
    "                start_text = i\n",
    "                res.append(replacer(st[start_quote: i]))\n",
    "        elif st[i] in '\"\\'':\n",
    "            quote = st[i]\n",
    "            if i < len(st) - 2 and st[i + 1] == st[i + 2] == quote:\n",
    "                quote = 3 * quote\n",
    "            start_quote = i + len(quote)\n",
    "            res.append(st[start_text: start_quote])\n",
    "        if st[i] == '\\n' and len(quote) == 1:\n",
    "            start_text = i\n",
    "            res.append(quote)\n",
    "            quote = ''\n",
    "        if st[i] == '\\\\':\n",
    "            i += 1\n",
    "        i += 1\n",
    "    return ''.join(res) + st[start_text:]\n",
    "\n",
    "#replace_literals('print(\"hel\\\\\"lo\")') + replace_literals(\"print('hel\\\\'lo world')\")\n",
    "replace_literals('this = \"wrong\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMMENT_RE = re.compile('#.*')\n",
    "python_code = []\n",
    "for fn in tqdm(srcs[:2000]):\n",
    "    try:\n",
    "        with open(fn, 'r', encoding=\"utf-8\") as fin:\n",
    "            src = fin.read()\n",
    "    except UnicodeDecodeError:\n",
    "        print('Could not read %s' % fn)\n",
    "    src = replace_literals(src)\n",
    "    src = COMMENT_RE.sub('', src)\n",
    "    python_code.append(src)\n",
    "\n",
    "python_code = '\\n\\n\\n'.join(python_code)\n",
    "len(python_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code = python_code[:5000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_chars = list(sorted(set(python_code)))\n",
    "py_char_to_idx = {ch: idx for idx, ch in enumerate(py_chars)}\n",
    "len(py_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"05.1 Python.source.txt\", \"w\") as f:\n",
    "    f.write(python_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "py_model = char_rnn_model(len(py_chars), num_layers=2, num_nodes=640, dropout=0)\n",
    "# py_model = char_rnn_model(94, num_layers=2, num_nodes=640, dropout=0)\n",
    "py_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "py_model = tf.keras.models.load_model(\"05 1 RNN_PyTorch_Code.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "early = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                              min_delta=0.03,\n",
    "                              patience=3,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "py_model.fit_generator(\n",
    "    data_generator(python_code, py_char_to_idx, batch_size=BATCH_SIZE, chunk_size=160),\n",
    "    epochs=30,\n",
    "    # callbacks=[early,],\n",
    "    steps_per_epoch=2 * len(python_code) / (BATCH_SIZE * 160),\n",
    "    verbose=1\n",
    ")                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "py_model.save(\"./05 1 RNN_Python2_Code.h5\",overwrite=True)\n",
    "# import os\n",
    "# os.system(\"shutdown /s /t 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "py_model = tf.keras.models.load_model(\"./05 1 RNN_PyTorch_Code.h5\")\n",
    "py_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_code(model, start_with='\\ndef ', end_with='\\n\\n', diversity=1.0):\n",
    "    generated = start_with\n",
    "    yield generated\n",
    "    for i in range(2000):\n",
    "        x = np.zeros((1, len(generated), len(py_chars)))\n",
    "        for t, char in enumerate(generated):\n",
    "            x[0, t, py_char_to_idx[char]] = 1.\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        \n",
    "        preds = np.asarray(preds[len(generated) - 1]).astype('float64')\n",
    "        preds = np.log(preds) / diversity\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        next_index = np.argmax(probas)        \n",
    "        next_char = py_chars[next_index]\n",
    "        yield next_char\n",
    "\n",
    "        generated += next_char\n",
    "        if generated.endswith(end_with):\n",
    "            break\n",
    "st=''\n",
    "for i in range(20):\n",
    "    for ch in generate_code(py_model):\n",
    "        sys.stdout.write(ch)\n",
    "        st += ch\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "flat_model = char_rnn_model(len(py_chars), num_layers=1, num_nodes=512, dropout=0)\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                              min_delta=0.03,\n",
    "                              patience=3,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "flat_model.fit_generator(\n",
    "    data_generator(python_code, py_char_to_idx, batch_size=BATCH_SIZE, chunk_size=160),\n",
    "    epochs=40,\n",
    "    callbacks=[early,],\n",
    "    steps_per_epoch=2 * len(python_code) / (BATCH_SIZE * 160),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_code = 'if a == 2:\\n    b=1\\nelse:\\n    b=2\\n'\n",
    "#example_code = 'a=(2 * 3)\\nb=(4 * 6 + 7)\\nreturn C'\n",
    "\n",
    "def activations(model, code):\n",
    "    x = np.zeros((1, len(code), len(py_char_to_idx)))\n",
    "    for t, char in enumerate(code):\n",
    "        x[0, t, py_char_to_idx[char]] = 1.\n",
    "    output = model.get_layer('lstm_layer_1').output\n",
    "    f = K.function([model.input], [output])\n",
    "    return f([x])[0][0]\n",
    "\n",
    "act = activations(flat_model, example_code)\n",
    "act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interesting_neurons(act):\n",
    "    res = []\n",
    "    for n in np.argmax(act, axis=1):\n",
    "        if not n in res:\n",
    "            res.append(n)\n",
    "    return res\n",
    "\n",
    "neurons = interesting_neurons(act)\n",
    "len(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_neurons(neurons, code, act, cell_size=12):\n",
    "    img = np.full((len(neurons) + 1, len(code), 3), 128)\n",
    "    scores = (act[:, neurons].T + 1) / 2\n",
    "    img[1:, :, 0] = 255 * (1 - scores)\n",
    "    img[1:, :, 1] = 255 * scores\n",
    "\n",
    "    f = BytesIO()\n",
    "    img = scipy.misc.imresize(img, float(cell_size), interp='nearest')\n",
    "    pil_img = PIL.Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    for idx, ch in enumerate(code):\n",
    "        draw.text((idx * cell_size + 2, 0), ch)\n",
    "    pil_img.save(f, 'png')\n",
    "    return Image(data=f.getvalue())\n",
    "\n",
    "img = visualize_neurons(neurons, example_code, act)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_for_code(code):\n",
    "    act = activations(flat_model, code)\n",
    "    neurons = interesting_neurons(act)\n",
    "    return visualize_neurons(neurons, code, act)\n",
    "\n",
    "display(image_for_code('if (a == 2) and ((b == 1) or (c==2)):'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 'if (a == 2) and ((b == 1) or (c==2)):'\n",
    "mask = '   ________     ____________________ '\n",
    "act = activations(flat_model, code)\n",
    "positive = [idx for idx, ch in enumerate(mask) if ch == '_']\n",
    "negative = [idx for idx, ch in enumerate(mask) if ch != '_']\n",
    "\n",
    "neurons = np.argsort(act[positive].sum(axis=0) - act[negative].sum(axis=0))[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = visualize_neurons(neurons, code, act)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act[negative, 108].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0\n",
    "x1 = 0\n",
    "for idx, ch in enumerate(mask):\n",
    "    if ch == '_':\n",
    "        x0 += act[idx, 108]\n",
    "    else:\n",
    "        x1 += act[idx, 108]\n",
    "x0, x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
